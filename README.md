# LLM Query System

An interactive system that retrieves web content based on user queries, processes the text, and generates AI-driven responses using a large language model (LLM).

## 🌐 Live Demo
[Live URL](https://llm-front-git-master-satyajit-patels-projects.vercel.app/)

## 🚀 Features
1. **Content Retrieval**: Searches the web, retrieves top relevant web pages, and extracts meaningful text.
2. **Text Processing**: Processes content to generate coherent input for the LLM.
3. **Response Generation**: Uses a language model to generate responses based on the query and processed text.
4. **Interactive Front-End**: User-friendly interface for inputting queries and receiving responses.

## 🛠️ Tech Stack
### Frontend:
- **React**
- **Tailwind CSS**
- **Vite**

### Backend:
- **Flask**
- **BeautifulSoup (for web scraping)**
- **OpenAI API**

## 📝 How to Run

### Backend (Flask):
```
1. Clone the repository:
   git clone https://github.com/satyajit-patel/LLM-Query.git

2. Navigate to the backend directory:
   cd llm-back

3. Activate virtual environment and install dependencies and run:
   python -m venv venv
   venv\Scripts\activate
   pip install -r requirements.txt
   flask --app index run
```

### Frontend (React):
```
1. Clone the repository:
   git clone https://github.com/satyajit-patel/LLM-Query.git
2. install dependencies and run it
   npm install
   npm run dev






